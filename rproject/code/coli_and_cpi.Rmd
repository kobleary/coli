---
title: 'Clean: COLI and CPI'
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages

```{r}
library(readxl)
library(sf)
library(stringr)
library(magrittr)
library(dplyr)
library(ggplot2)
```

## Read the data

```{r}
coli_path <- "data sets/COLI Historical Data - 1990 Q1 - 2019 Q1.xlsx"
coli <- read_excel(coli_path)

coli_counts_path <- "data sets/COLI_CITIES_beta.xlsx"
coli_counts <- read_excel(coli_counts_path)

cpi_path <- "data sets/CPI Data_Final.xlsx"
cpi <- read_excel(cpi_path)
```
* * *

# CPI 

## Spell-check CPI Cities

```{r}
cpi %<>%
  dplyr::rename(city = City) %>%
  dplyr::group_by(city) %>%
  dplyr::mutate(n_years = n())

# Table of cities and the number of years they've been observed
cpi %>%
  dplyr::group_by(city) %>%
  dplyr::summarise(n_years = n_years[1]) %>%
  arrange(n_years)

cpi$city <- plyr::revalue(cpi$city, 
        c("Cleveland-Akron" = "Cleveland", 
          "Dallas-Forth Worth-Arlington" = "Dallas-Fort Worth-Arlington", 
          #"Los Angeles-Riverside-Orange County" = "Los Angeles-Long Beach-Anaheim",
          "Cincinnati-Hamilton" = "Cincinnati",
          "Pheonix-Mesa-Scottsdale" = "Phoenix-Mesa-Scottsdale",
          "San Diego-Carsbad" = "San Diego-Carlsbad",
          "Urban Hawaii" = "Urban Honolulu",
          "Portland-Salem" = "Portland-Vancouver-Hillsboro"))
```
* * *

# COLI

## Get most frequently seen COLI cities

There are 91 cities observed at least once a year. 

```{r}
coli$city <- coli$URBAN_AREA_NAME

# Count frequency per year
counts <- table(coli$URBAN_AREA_NAME, coli$YEAR)

# Find all the entries in the table where the yearly counts are 0 and sum
# the true/false over all years.
zeroes <- rowSums(counts == 0)

# We're interested in the cities that were observed at least once a year, 
# save the names of these in a list
coli_greatest_hits <- names(zeroes[zeroes == 0])
```

## Join UA geometries

```{r}
uas <- st_read("shapefiles/tl_2017_us_uac10/tl_2017_us_uac10.shp")

# Transform UA city names to the format from COLI
ua_input <- paste(uas$NAME10, collapse = "|")
ua_alias <- str_replace_all(string = ua_input, pattern = ", ", replacement = " ")
ua_alias <- strsplit(ua_alias, split = "\\|")
ua_alias <- unlist(ua_alias)

# Save transformed city names in new column
uas$city <- ua_alias

```

## Join CBSA geometries from US Census Bureau

```{r}
cbsas <- st_read("shapefiles/tl_2017_us_cbsa/tl_2017_us_cbsa.shp")
# Keep only the city name, drop the state. Extract city transforms 
# "Portland, OR" -> "Portland"
extractCity <- function(string){
    unlist(str_split(string, ", "))[1]
}

# Save shorter cities in new column
cbsas$city <- sapply(cbsas$NAMELSAD, extractCity) 

# gives list of only the metropolitan (excluding micropolitan) area names
metro_areas <- cbsas$NAMELSAD[grepl("Metro", cbsas$NAMELSAD)]
metro_areas <- sapply(metro_areas, extractCity)

cbsas_metro <- cbsas %>%
  filter(grepl("Metro", NAMELSAD)) %>%
  select(city, NAMELSAD) 

```

## Calculate distances 

Join the geometries from the CBSA and UA shapefiles loaded above. In order to calculate distances, I collapse the CPI and COLI data by city (ending up with one row per city to avoid lugging around extra copies of the same geometry with each year). Then calculate the centroids of each city's geometry, and use `st_distance()` from the sf package to calculate the distances from each COLI city to each CPI city. This results in a 359 x 22 matrix where the names of the nearest city are found and saved in a crosswalk data frame. 

The crosswalk data frame with each COLI and the corresponding nearest CPI will help us join the correct CPI city to the COLI. 

```{r}
# Calculate minimum distance centroid for each polygon
cpi_geo <- left_join(cbsas, cpi, by = "city") %>%
  filter(!is.na(State))
coli_geo <- left_join(uas, coli, by = "city") %>%
  filter(!is.na(QUARTER))

coli_geo_trim <- coli_geo %>%
  dplyr::group_by(city) %>%
  dplyr::summarize(n = n()) 

coli_geo_trim$centroid <- coli_geo_trim %>%
  st_transform(29101) %>% 
  st_centroid() %>% 
  # this is the crs from d, which has no EPSG code:
  st_transform(., '+proj=longlat +ellps=GRS80 +no_defs') %>%
  # since you want the centroids in a second geometry col:
  st_geometry()

cpi_geo_trim <- cpi_geo %>%
  dplyr::group_by(city) %>%
  dplyr::summarize(n = n()) %>%
  dplyr::filter(n > 50)

cpi_geo_trim$centroid <- cpi_geo_trim %>%
  st_transform(29101) %>% 
  st_centroid() %>% 
  # this is the crs from d, which has no EPSG code:
  st_transform(., '+proj=longlat +ellps=GRS80 +no_defs') %>%
  # since you want the centroids in a second geometry col:
  st_geometry()

# Calculate distances between centroid of each city
dist.matrix <- st_distance(coli_geo_trim$centroid, 
                           cpi_geo_trim$centroid)

colnames(dist.matrix) <- cpi_geo_trim$city
rownames(dist.matrix) <- coli_geo_trim$city
```

## Create excel spreadsheet with CPI counts
```{R}
coli$nearest_cpi <- NA
for(y in 1:2018){
  y <- 1990
  coli_city <- coli %>%
    filter(YEAR == y) %>%
    pull(URBAN_AREA_NAME) %>% unique()
  
  cpi_city <- cpi %>%
    filter(Year == y) %>%
    pull(city) %>% unique() %>%
    as.character()
  
  dist.df <- as.data.frame(dist.matrix)
  cols <- colnames(dist.matrix)[colnames(dist.matrix) %in% cpi_city]
  
  dist.df <- subset(dist.df, rownames(dist.matrix) %in% coli_city) %>%
    select(cols)
  
  min_dist <- apply(dist.df, 1, function(row) which.min(row))

  nearest_cpi <- colnames(dist.df)[unlist(min_dist)]
  
  coli[coli$YEAR == y,]$nearest_cpi <- nearest_cpi
}
```



```{R}
# 60-length vector of indicies denoting which column index has the smallest distance from the place
# located in row i.
min_dist <- apply(dist.matrix, 1, function(row) which.min(row))
min_dist_trim <- min_dist[names(min_dist) %in% coli_greatest_hits]

nearest_cpi <- colnames(dist.matrix)[unlist(min_dist_trim)]

# Fairbanks did not have an associated closest cpi
cpi_coli_crosswalk <- data.frame(nearest_coli = dplyr::setdiff(names(min_dist_trim), 
                                       "Fairbanks AK"),
           nearest_cpi = nearest_cpi) %>%
  mutate(city = nearest_coli)
```

## Find minimum distance by year

```{r}
cpi_geo$centroid <- cpi_geo %>%
  st_transform(29101) %>% 
  st_centroid() %>% 
  # this is the crs from d, which has no EPSG code:
  st_transform(., '+proj=longlat +ellps=GRS80 +no_defs') %>%
  # since you want the centroids in a second geometry col:
  st_geometry()

coli_geo$centroid <- coli_geo %>%
  st_transform(29101) %>% 
  st_centroid() %>% 
  # this is the crs from d, which has no EPSG code:
  st_transform(., '+proj=longlat +ellps=GRS80 +no_defs') %>%
  # since you want the centroids in a second geometry col:
  st_geometry()

dist.matrix <- st_distance(coli_geo$centroid, 
                           cpi_geo$centroid)

colnames(dist.matrix) <- cpi_geo$city
rownames(dist.matrix) <- coli_geo$city

# 60-length vector of indicies denoting which column index has the smallest distance from the place
# located in row i.
min_dist <- apply(dist.matrix, 1, function(row) which.min(row))
min_dist_trim <- min_dist[names(min_dist) %in% coli_greatest_hits]

```


## Create mapping between COLI and CPI

We'll use Houston TX as the base city whose index every year will be the denominator in our new index. Because the sample of cities changes each quarter, the new indicies generated can be thought of as the price level relative to Houston. 
```{r}
# Names: COLI - Houston TX, CPI - Houston-The Woodlands-Sugar Land

# Create separate data frame with only Houston's COLI values over time (filter
# out all other cities)
houston <- coli %>%
  filter(city == "Houston TX") %>%
  dplyr::mutate(time = paste0(as.character(YEAR), QUARTER)) %>%
  dplyr::rename(BASE_INDEX = COMPOSITE_INDEX) %>%
  select(BASE_INDEX, time)

# Join the Houston indicies by year-quarter combos (note: these should
# be identical across cities but vary across time)  
coli %<>% 
  dplyr::mutate(time = paste0(as.character(YEAR), QUARTER)) %>%
  dplyr::left_join(houston, by = "time")

# Generate new_index column that scales each index by Atlanta's
# index. So Atlanta's index will be equal to 100 each quarter. 
coli %<>%
  dplyr::mutate(new_index = (COMPOSITE_INDEX / BASE_INDEX) * 100)
```


## Connect scaled COLI indicies to CPI time trend

First we'll join the corresponding CPI cities to each COLI observation by the city name, then add a column `cpi_city_trend` takes COLI `new_index` value, multiplies it by the corresponding city's CPIu value, then divides by 100. 

```{r}
# Join cpi to coli
coli %<>%
  left_join(cpi_coli_crosswalk, by = "city")

coliq2 <- coli %>% 
  filter(!is.na(nearest_cpi), QUARTER == "Q2") %>%
  left_join(cpi, by = c("nearest_cpi" = "city", "YEAR" = "Year")) %>%
  mutate(cpi_time_trend = new_index * CPIu / 100) %>%
  select(YEAR, QUARTER, city, nearest_cpi, CPIu, COMPOSITE_INDEX, 
         BASE_INDEX, new_index,
         cpi_time_trend, n_years, everything())



```

Note that we have some missing data due to the introduction or reshaping of CPI cities, like the introduction of the CPI geography Washington-Baltimore in 1996 and Phoenix-Mesa-Scottsdale CPI in 2002. We can decide if we need to adjust the CPI-COLI pairs to account for these geographic sampling differences. 

## Graphs

```{r}
# var(testy$CPIu, na.rm = T)
# var(testy$COMPOSITE_INDEX)
# var(testy$cpi_time_trend, na.rm = T)
# 
# graphy <- ggplot(data = testy %>% filter(city == "Spokane WA"),
#                  aes(x = YEAR, y = cpi_time_trend)) + 
#   geom_line() +
#   labs(title = "Spokane, WA COLI index time-trended to CPI") 
# #graphy
# 
# graphy2 <- ggplot(data = testy %>% filter(city == "Spokane WA"), 
#                   aes(x = YEAR, y = CPIu)) + 
#   geom_line() +
#   labs(title = "Spokane, WA CPI") 
#graphy2
```
* * *

## Quantifying loss

```{R}


```




